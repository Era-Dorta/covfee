---
title: Continuous Keypoint
---

import {TaskPlayground} from '../../src/utils/task_playground'

The continuous keypoint task was created for annotation of keypoints in a video. In the original application these keypoints corresponded to extremities of people in a social interaction. The task makes use of an optical flow video to play the video slower when the mouse cursor is close to moving parts, to aid annotators in the process. Skeletal keypoints were annotated one-by-one continuously, instead of traditional frame-based annotation in which some image frames are annotated to then be interpolated. In general, this task is especially useful when the target keypoint are visible for long periods of time.

:::caution
This task requires the use of desktop Google Chrome as it relies on [requestVideoFrameCallback()](https://wicg.github.io/video-rvfc/)
:::

## Automatic speed adjustment

Covfee solves the problem of continuously annotating keypoints via a new annotation technique, which consists in the automatic adjustment of the playback rate of the video in real time, according to the magnitude of the optical flow around the mouse cursor. The rate is adjusted such that it is higher when the optical flow is high and lower when optical flow is little around the mouse cursor. This has the effect of slowing down the video when the joint being tracked moves fast and speeding up the video for slow-moving or static joints. It allows the users to annotate slow-moving joints at multiples of real time rate (eg. 4x playback rate), and fast gestures at fractions of it (eg. 0.1x playback rate) on the fly without additional user intervention.

Concretely, for a cursor position $x,y$ (in pixels) at frame $f$ an $N x N$ neighborhood in the vicinity of $(x,y)$ is considered, such that the playback rate at frame $f+1$ is given by: 

$$
r_{f+1} = C \cdot \sum_{i=x-N/2} ^ {x+N/2} \sum_{i=y-N/2} ^ {y+N/2} |O_{f,i,j}|
$$

where $O_{f,x,y}$ is the optical flow vector for frame $f$ at image location $(x, y)$ and $C$ is a constant. The best value of $N$ depends on the video being annotated, and is a configurable parameter.

This rate is additionally bounded to prevent extremely low or high playback rates and a user-controllable multiplier $C_u$ is added to allow the user to control the overall playback rate:

$$
r = C_u * max(r_{min}, min(r_{max}, r_i))
$$

The rate $r$ (equivalently, the delay until the next frame) is adjusted on every frame. This can only be implemented efficiently online if the flow computation is done offline and only the local averaging is calculated in the user's machine. For this, Covfee makes use of a pre-computed optical flow video.



## Optical flow pre-computation

For automatic speed adjustment, this task requies expects input videos to contain the original video and its corresponding optical flow video stacked side by side. An input video to the task looks like the following:

<video style={{width:'100%'}} src="https://cdn.jsdelivr.net/gh/josedvq/covfee@master/samples/keypoints/www/sign_combined.mp4"/>

Covfee uses the right side of the video for optical flow computation and only displays the left side to the user. An easy way to create the stacked video is:

1. Use [this script](https://github.com/josedvq/covfee/blob/master/samples/keypoints/utils/flow.py) to extract the optical flow of your video into a new mp4 file:

```
python flow.py --video /path/to/video.mp4 --flow /path/to/flow.mp4 --width VIDEO_WIDTH
```

Replace `VIDEO_WIDTH` with the pixel width of your input video (`video.mp4` in this case).

2. Stack the videos horizontally. You can use FFMPEG for this: 
```
ffmpeg -i /path/to/video.mp4 -i /path/to/flow.mp4 -filter_complex hstack video_combined.mp4
```

The output file `video_combined.mp4` can be used as input for a keypoint task.

:::caution
Optical flow can be extremely unreliable for videos with high noise (eg. low lighting conditions). Input videos might need to be denoised before optical flow pre-computation. We had good results with ffmpeg's [hqdn3d](https://ffmpeg.org/ffmpeg-filters.html#hqdn3d-1):

```
ffmpeg -i input.mp4 -vf hqdn3d=luma_tmp=20 -vcodec libx264 -tune film output.mp4 -y
```
:::

## Playground

export const playgroundTasks = [
    {
        'schema': 'ContinuousKeypointTaskSpec',
        'label': 'Basic',
        'spec': {
            "name": "Continuous annotation example",
            "type": "ContinuousKeypointTask",
            "media": {
                "type": "video",
                resolution: [1280, 720],
                "url": "https://cdn.jsdelivr.net/gh/josedvq/covfee@master/samples/keypoints/www/sign_combined.mp4",
                "hasFlow": true,
                "fps": 59.94,
            }
        }
    }
]

<TaskPlayground tasks={playgroundTasks} />

